# 11. Uso de la caché para optimizar el rendimiento y el tiempo de carga

## ¿Por qué es importante el caching en Streamlit?

Streamlit ejecuta el script completo cada vez que el usuario interactúa con la aplicación. Sin caching, esto podría resultar en operaciones redundantes y costosas que ralentizan la aplicación. El caching permite reutilizar resultados previamente calculados, lo que mejora significativamente el rendimiento y la experiencia del usuario.

En Streamlit, el uso de `@st.cache_data` y `@st.cache_resource` es fundamental para mejorar el rendimiento de las aplicaciones, especialmente cuando se trabaja con operaciones costosas en términos de tiempo o recursos, como la carga de datos o la inicialización de modelos de machine learning.

[Cacheo en Streamlit](https://docs.streamlit.io/develop/concepts/architecture/caching)

### `@st.cache_data`

Este decorador se utiliza para cachear los resultados de funciones que cargan o procesan datos. Al cachear estos resultados, evitas que la función se ejecute nuevamente si los parámetros de entrada no han cambiado, lo que acelera la ejecución de la aplicación.

Parámetros:

- **`ttl` (Time To Live)**: Especifica el tiempo en segundos que los datos deben permanecer en la caché antes de ser eliminados. Esto es útil para datos que pueden cambiar con el tiempo, como datos de una API que se actualiza periódicamente.
- **`show_spinner`**: Si se establece en `True`, muestra un spinner en la interfaz de usuario mientras se cargan o procesan los datos. Esto mejora la experiencia del usuario al indicar que la aplicación está trabajando.
- **`show_time`**: Si se establece en `True`, muestra el tiempo que tarda en ejecutarse la función cacheada.
- **`max_entries`**: Limita el número de entradas en la caché. Si se supera este límite, las entradas más antiguas se eliminan para hacer espacio a las nuevas.
- **`hash_funcs`**: Diccionario que mapea tipos o nombres calificados completos a funciones hash. Esto se utiliza para anular el comportamiento del hasher dentro del mecanismo de caché de Streamlit: cuando el hasher encuentra un objeto, primero verifica si su tipo coincide con una clave en este diccionario y, si es así, utiliza la función proporcionada para generar un hash para él.
- **`persist`**: Si se establece en `True`, la caché se guarda en disco para que persista entre ejecuciones de la aplicación. Esto es útil para datos que no cambian con frecuencia y que son costosos de recalcular.

Más información: [st.cache_data](https://docs.streamlit.io/develop/api-reference/caching-and-state/st.cache_data)

Ejemplo:

```python
@st.cache_data(ttl=3600, show_spinner=True, max_entries=10)
def load_data(url):
    data = pd.read_csv(url)
    return data
```

### `@st.cache_resource`

Este decorador es similar a `@st.cache_data`, pero está diseñado para cachear recursos que deben estar disponibles globalmente en la aplicación, como conexiones a bases de datos, modelos de machine learning, o cualquier otro recurso que sea costoso de inicializar.

- **`ttl`**: Igual que en `@st.cache_data`, especifica el tiempo en segundos que el recurso debe permanecer en la caché.
- **`show_spinner`**: Muestra un spinner mientras se inicializa el recurso.
- **`max_entries`**: Limita el número de recursos en la caché.
- **`hash_function`**: Permite especificar una función personalizada para generar un hash de los argumentos.

Ejemplo:

```python
@st.cache_resource(ttl=3600, show_spinner=True)
def load_model():
    model = torch.load('model.pth')
    return model
```

### Diferencias clave entre `@st.cache_data` y `@st.cache_resource`

- **`@st.cache_data`**: Se utiliza para cachear datos que son el resultado de una función. Estos datos se almacenan en memoria y se invalidan si los parámetros de la función cambian.
- **`@st.cache_resource`**: Se utiliza para cachear recursos que deben ser compartidos y reutilizados en toda la aplicación, como conexiones a bases de datos o modelos de machine learning. Estos recursos no se invalidan tan fácilmente y están diseñados para ser persistentes.

> En versiones anteriores de Streamlit existía el decorador `@st.cache`, pero a partir de **Streamlit 1.18.0**, este fue **deprecado** (obsoleto) y reemplazado por dos decoradores más específicos y optimizados: `@st.cache_data` y `@st.cache_resource`. No estaba claro si el decorador debía usarse para cachear datos (como DataFrames) o recursos (como conexiones a bases de datos o modelos). Esto podía llevar a errores o malas prácticas.
